

services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.3.0
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181

  kafka:
    image: confluentinc/cp-kafka:7.3.0
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1

  ollama:
    build:
      context: .
      dockerfile: Dockerfile.ollama
    container_name: ollama
    runtime: nvidia
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [ gpu ]
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - OLLAMA_BACKEND=cuda
      - OLLAMA_HOST=0.0.0.0:11434
    ports:
      - "11434:11434"
    volumes:
      - ./models:/root/.ollama/models
    restart: unless-stopped
    entrypoint: [ "/bin/sh", "-c" ]
    command:
      - |
        echo "üöÄ –ó–∞–ø—É—Å–∫–∞–µ–º Ollama..."
        OLLAMA_BACKEND=cuda ollama serve &  # –ó–∞–ø—É—Å–∫ –≤ —Ñ–æ–Ω–µ
        echo "‚è≥ –î–∞–µ–º Ollama 5 —Å–µ–∫—É–Ω–¥ –Ω–∞ –∑–∞–ø—É—Å–∫..."
        sleep 5
        echo "üõ† –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–±–æ—Ç—É —Å–µ—Ä–≤–µ—Ä–∞..."
        until curl -s http://localhost:11434/api/tags > /dev/null; do
          echo "‚ö†Ô∏è  Ollama –µ—â–µ –Ω–µ –ø–æ–¥–Ω—è–ª—Å—è, –∂–¥–µ–º..."
          sleep 2
        done
        echo "‚úÖ Ollama –∑–∞–ø—É—â–µ–Ω, –∑–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª–∏..."
        if ! ollama list | grep -q 'hf.co/Vikhrmodels/Vikhr-Llama-3.2-1B-instruct-GGUF:F16'; then
          echo "üì• –ó–∞–≥—Ä—É–∂–∞–µ–º hf.co/Vikhrmodels/Vikhr-Llama-3.2-1B-instruct-GGUF:F16..."
          ollama pull hf.co/Vikhrmodels/Vikhr-Llama-3.2-1B-instruct-GGUF:F16
        fi
        if ! ollama list | grep -q 'deepseek-r1:1.5b'; then
          echo "üì• –ó–∞–≥—Ä—É–∂–∞–µ–º deepseek-r1:1.5b..."
          ollama pull deepseek-r1:1.5b
        fi
        echo "‚úÖ –í—Å–µ –≥–æ—Ç–æ–≤–æ!"
        wait
#    networks:
#      - Ollama_DS

  redis:
    image: redis:alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data

  fastapi:
    build: ./server
    ports:
      - "8000:8000"
    restart: unless-stopped
    depends_on:
      - kafka
      - redis

  consumer:
    build: ./ollama_app
    environment:
      - OLLAMA_API=http://localhost:11434
    depends_on:
      - kafka
      - ollama
      - redis
    restart: unless-stopped

  app:
    build: ./tg_bot
    container_name: telegram_bot_app
    environment:
      TELEGRAM_BOT_KEY: YOUR_API_KEY
    depends_on:
      - fastapi




volumes:
  ollama_data:
  redis_data:

#networks:
#  Ollama_DS:
#    driver: bridge